# üèóÔ∏è Arquitetura MangaAutoColor Pro v3.0 (ADR 006)

## Vis√£o Geral

O MangaAutoColor Pro utiliza uma arquitetura **Two-Pass** enterprise-grade, otimizada para **GPU Consumer (RTX 3060 12GB)**. A arquitetura evoluiu para focar em **Modularidade**, **Testabilidade** e **Controle Regional**.

### üåü Pilares da Arquitetura v3.0
1.  **Pipeline Two-Pass**: An√°lise (CPU) e Gera√ß√£o (GPU/VRAM).
2.  **Engine V3 (SD 1.5)**: Alta fidelidade de tra√ßo com ControlNet Lineart e Multiply Mode.
3.  **Global Identity**: Consist√™ncia via IP-Adapter com refer√™ncia visual √∫nica por personagem.
4.  **Data-Driven**: Persist√™ncia robusta (Parquet + FAISS) e logs estruturados.
5.  **Quality Assurance**: Suite de testes automatizada com **AVQV (Automated Visual Quality Validation)**.

---

## üèóÔ∏è Diagrama de Estrutura (Componentes)

```mermaid
graph TD
    classDef core fill:#e1f5fe,stroke:#01579b
    classDef service fill:#f3e5f5,stroke:#4a148c
    classDef data fill:#e8f5e9,stroke:#1b5e20
    classDef ext fill:#fff3e0,stroke:#e65100

    User[User Input] -->|Chapter| API[FastAPI / CLI]
    API --> Pipeline[MangaColorizationPipeline]:::core

    subgraph "Pass 1: Analysis (CPU Bound)"
        Pipeline --> P1[Pass1Analyzer]:::core
        P1 --> YOLO[YOLODetector (Manga109)]:::ext
        P1 --> Scene[SceneDetector (Narrative)]:::service
        P1 --> Palette[PaletteExtractor (CIELAB)]:::service
        P1 --> ID[HybridIdentityEncoder (CLIP+Face)]:::service
        
        P1 --> DB[(ChapterDatabase)]:::data
    end

    subgraph "Data Layer"
        DB --> HS[CharacterService]:::service
        DB --> NS[NarrativeService]:::service
        DB --> TS[TileService]:::service
        DB --> VI[VectorIndex (FAISS)]:::data
        DB --> PQ[Parquet Metadata]:::data
    end

    subgraph "Pass 2: Generation (GPU Bound)"
        Pipeline --> P2[Pass2Generator]:::core
        P2 --> E3[SD15LineartEngine]:::core
        
        E3 --> PB[MangaPromptBuilder]:::service
        E3 --> TM[TilingManager]:::service
        E3 --> TC[TextCompositor]:::service
        
        E3 --> SD15[SD 1.5 UNet]:::ext
        E3 --> IP[IP-Adapter Plus]:::ext
        E3 --> CN[ControlNet Lineart]:::ext
    end

    SD15LineartEngine -->|Bubble Masking| E3
    E3 -->|Gaussian Blur| E3
    E3 -->|Multiply Blend| Output[Colorized Page]
```

## üîÑ Fluxo de Processamento (Pipeline)

### Passo 1: An√°lise e Enriquecimento
O objetivo √© extrair **todo** o contexto necess√°rio antes de tocar na GPU.

1.  **Ingest√£o H√≠brida**: O endpoint `/chapter/analyze` aceita tanto p√°ginas P/B quanto refer√™ncias coloridas (opcional).
2.  **Detec√ß√£o (YOLO)**: Identifica `body`, `face`, `frame`, e `text`.
    *   *Nota*: Bal√µes de texto (class 3) s√£o preservados explicitamente.
3.  **Narrative Context**: Classifica a cena (ex: "flashback", "night", "outdoors") via `SceneDetector`.
4.  **Identidade H√≠brida**: Extrai embeddings CLIP (global) e ArcFace (facial) para cada personagem.
5.  **Consolida√ß√£o (Clustering)**: `CharacterService` agrupa detec√ß√µes do mesmo personagem usando FAISS, unificando refer√™ncias coloridas (se houver) com ocorr√™ncias nas p√°ginas.
6.  **Persist√™ncia**: Tudo √© salvo em `output/{chapter_id}/cache/`.

### Passo 2: Gera√ß√£o Tile-Aware
A gera√ß√£o √© agn√≥stica √† resolu√ß√£o e focada em efici√™ncia de VRAM.

1.  **Prompt Building**: `MangaPromptBuilder` constr√≥i prompts baseados em:
    *   Descri√ß√£o da Cena (`SceneType`)
    *   Paletas de Cores (CIELAB)
    *   Style Presets (Config)
2.  **Generation Strategy**:
    *   **Single Pass (v3.0)**: Processamento de p√°gina inteira (Full Page) para m√°xima coer√™ncia global.
    *   **Resolution Handling**: SD 1.5 √© nativo em 512px. Gera√ß√£o em 1024px (Single Pass) depende fortemente do **ControlNet** para evitar duplica√ß√£o de estruturas (ex: dois corpos).
    *   *Nota*: V3.1 trar√° Tiling real para mitigar riscos de alucina√ß√£o em alta resolu√ß√£o.
3.  **Identity Strategy (Global & Regional)**:
    *   **Regional IP-Adapter**: Suporta m√∫ltiplos personagens por tile. O `Pass2Generator` cria m√°scaras de aten√ß√£o baseadas nos BBoxes, garantindo que cada refer√™ncia visual condicione apenas a regi√£o correta.
    *   **Dynamic Control**: Aplica-se apenas nos primeiros 60% dos steps (configur√°vel via `IP_ADAPTER_END_STEP`) para garantir estrutura sem comprometer detalhes finos.
    *   **Text Prompt Augmentation**: O `MangaPromptBuilder` usa o `PaletteExtractor` (CIELAB) para converter cores das refer√™ncias em texto (ex: "blue hair"), refor√ßando a consist√™ncia.
4.  **Compositing & Bubble Masking**:
    *   **Bubble Masking**: O motor identifica regi√µes de texto via YOLO e as limpa (preenche com branco puro) na camada de cor gerada. Isso elimina "ghosting" e cores indesejadas dentro dos bal√µes.
    *   **Soft Composition**: Aplica-se um leve Gaussian Blur (radius=0.5) na camada de cor antes do Multiply. Isso suaviza halos e "serrilhados" na intersec√ß√£o entre cores e linhas.
    *   **Text Restoration**: O `TextCompositor` restaura o texto original com nitidez total.

---

## üé® Estrat√©gia de Coloriza√ß√£o

A engine v3.0 decide dinamicamente a fonte das cores baseada na disponibilidade de refer√™ncias:

### 1. Com Refer√™ncia (Character-Driven)
Quando o usu√°rio faz upload de imagens coloridas junto com o cap√≠tulo (via **Extension UI** ou API):
*   **Ingest√£o:** O sistema recebe refer√™ncias em campo separado da API (`color_references`), evitando confus√£o com p√°ginas do mang√°.
*   **Matching:** **Autom√°tico (Threshold 0.95)**. O `CharacterService` usa FAISS para agrupar refer√™ncias aos personagens detectados.
    *   *Nota*: N√£o h√° interface manual de corre√ß√£o nesta vers√£o.
*   **Gera√ß√£o:** O IP-Adapter recebe a imagem de refer√™ncia do cluster para guiar a coloriza√ß√£o daquele personagem espec√≠fico.
*   **Resultado:** Consist√™ncia visual mantida (roupas, cabelo, pele) atrav√©s das p√°ginas.

### 2. Sem Refer√™ncia (Zero-Shot / Style Preset)
Quando nenhuma refer√™ncia √© fornecida:
*   **Ingest√£o:** Apenas p√°ginas P/B s√£o analisadas.
*   **Coloriza√ß√£o:** O sistema utiliza `ControlNet Lineart` + `Prompt Engineering`.
*   **Style Presets:** O usu√°rio escolhe um preset (ex: "vibrant", "muted", "pastel") no momento da gera√ß√£o.
*   **Resultado:** A IA "alucina" cores coerentes com o estilo escolhido, mantendo o tra√ßo original perfeito, mas sem garantia de consist√™ncia de cores espec√≠ficas entre p√°ginas (ex: a camisa pode mudar de cor se n√£o houver refer√™ncia).

---

## üß© Componentes Chave (Decoupled Services)

A partir da v2.6, classes monol√≠ticas foram refatoradas em servi√ßos especializados:

### 1. SD15LineartEngine (`core/generation/engines/sd15_lineart_engine.py`)
Novo motor de gera√ß√£o baseado em SD 1.5.
*   **Model**: `runwayml/stable-diffusion-v1-5`.
*   **ControlNet**: `lllyasviel/control_v11p_sd15s2_lineart_anime` (Espec√≠fico para Anime).
*   **Preprocessor**: Nenhum (Implicit). O sistema assume que a entrada j√° √© um Lineart (Manga P/B), alimentando a imagem original diretamente no ControlNet.
*   **Feature**: Preserva√ß√£o perfeita de tra√ßo via ControlNet Lineart + Multiply Mode.
*   **Mecanismo**: Inpainting regional + Composi√ß√£o final em modo Multiply.
*   **Consist√™ncia**: IP-Adapter global por personagem (refer√™ncia visual).

### 2. TilingManager (`core/generation/tiling.py`)
(Em desenvolvimento para v3.1)
*   Planejado para gerenciar subdivis√£o de p√°ginas 4K+.
*   Atualmente, o sistema opera em modo **Single Tile** (Full Page) para garantir coer√™ncia.
*   Gerencia o "Change Map" (m√°scaras Gaussianas para blending).
*   Filtra quais personagens aparecem em qual tile.

### 3. TextCompositor (`core/generation/text_compositor.py`)
Respons√°vel pela preserva√ß√£o de texto (SRP).
*   Recebe a imagem original e a gerada.
*   Recebe m√°scaras de texto (do YOLO).
*   Aplica `seamlessClone` ou alpha blending para restaurar o texto com nitidez perfeita.

### 4. MangaPromptBuilder (`core/generation/prompt_builder.py`)
Encapsula a l√≥gica de engenharia de prompt.
*   Converte paletas CIELAB/HSL em nomes de cores.
*   Aplica modificadores de cena e estilos.

### 5. ScenePaletteService (`core/generation/scene_palette_service.py`)
Novo em v3.0.
*   **Responsabilidade**: Garantir consist√™ncia determin√≠stica para coadjuvantes (Zero-Shot).
*   **Mecanismo**: Hash(char_id) -> HSL -> Harmoniza√ß√£o com Protagonistas -> Prompt Injection.
*   **Persist√™ncia**: `scene_palette.json` por cap√≠tulo.

### 6. AVQV: Automated Visual Quality Validation (`tests/integration/test_visual_quality_regression.py`)
Novo framework de testes para prevenir regress√µes visuais subjetivas.
*   **M√©trica: Bubble Purity**: Analisa a vari√¢ncia de cor em regi√µes de texto. (Detecta bal√µes sujos).
*   **M√©trica: Edge Neutrality**: Compara a cromin√¢ncia nas bordas vs centro para detectar artefatos de VAE Tiling.
*   **M√©trica: Dynamic Range**: Verifica picos de histograma para detectar "solariza√ß√£o".

---

## üß™ Estrat√©gia de Testes (Quality Assurance)

A suite de testes (v2.6.3) garante estabilidade e previne regress√µes.

### Estrutura
*   `tests/unit/`: Testes isolados de componentes (sem IO/GPU).
    *   Ex: `test_text_compositor.py`, `test_prompt_builder.py`.
*   `tests/integration/`: Testes de componentes reais com IO (File system/Database).
    *   Ex: `test_pass1.py` (roda an√°lise real), `test_chapter_db.py`.
*   `tests/e2e/`: Simula√ß√£o completa do pipeline (Mocked Models).
    *   Ex: `test_pipeline.py` (Simula Pass 1 -> Pass 2).

### Execu√ß√£o
O script `run_tests.bat` orquestra a execu√ß√£o no ambiente correto (`venv`):
```batch
run_tests.bat  # Roda Unit, Integration e E2E em sequ√™ncia
```

---

## üìä Performance (Benchmark RTX 3060 - v3.0)

| Modo | Resolu√ß√£o | Tempo M√©dio | VRAM |
|------|-----------|-------------|------|
| **Single Tile** | 1024x1408 | ~25s | ~8.0 GB |
| **Multi-Tile** | 2048x2816 | ~90s | ~8.5 GB |

*   **Nota**: Aumento de tempo justificado pelo salto dram√°tico na qualidade (4 steps -> 20 steps).
*   **VRAM**: Consumo menor que SDXL, permitindo maior estabilidade.

*   **VRAM Management**: O sistema usa `enable_model_cpu_offload()` agressivo. O pico de VRAM ocorre durante o decode VAE.
*   **Concurrency**: O processamento √© sequencial por GPU, mas thread-safe para API server.

---

## üìÖ Hist√≥rico de Mudan√ßas Arquiteturais

| Vers√£o | Mudan√ßa Principal | Motivo |
|--------|-------------------|--------|
| **v2.0** | Two-Pass Architecture | Separar IO de GPU, permitir cache. |
| **v2.3** | Single Tile Optimization | SDXL nativo (1024px) √© melhor que Tiling for√ßado. |
| **v2.5** | Regional IP-Adapter | Resolver "color bleeding" entre personagens. |
| **v2.6** | Decoupled Services | Reduzir complexidade ciclom√°tica e acoplamento. |
| **v2.6.3**| Test Suite Upgrade | Garantir estabilidade em produ√ß√£o. |
| **v2.6.4**| Z-Ordering Anti-Halo | Solu√ß√£o para overlap de m√°scaras via subtra√ß√£o bin√°ria e blur final. |
| **v2.7** | ADR 005 - PCTC | Point Correspondence & Temporal Consistency. |
| **v3.0** | ADR 006 - Engine Replacement | Troca de SDXL por SD 1.5 + Lineart (Multiply Mode). Remo√ß√£o de ADR 005. |

## ‚úÖ Implementado: ADR 004 & ADR 006

### ADR 004: Segmenta√ß√£o Sem√¢ntica (SAM 2.1) & Z-Buffer ‚úÖ
**Status:** IMPLEMENTADO (v2.6.5)

*   **SAM 2.1 Tiny:** Segmenta√ß√£o densa edge-preserving (35MB).
*   **Z-Buffer Hier√°rquico:** Ordena√ß√£o de profundidade autom√°tica (Y + √Årea + Tipo).
*   **Documenta√ß√£o:** [ADR 004](ADR_004_SAM2_Segmentation.md).

### ADR 006: Engine Replacement (SD 1.5 + Lineart) ‚úÖ
**Status:** IMPLEMENTADO (v3.0.0)

*   **Engine:** SD 1.5 Base + ControlNet Anime Lineart.
*   **Composi√ß√£o:** Inpainting + Multiply Blending para preto perfeito.
*   **Consist√™ncia:** IP-Adapter Global.
*   **Documenta√ß√£o:** [ADR 006](ADR%20006).

### üö´ Removido: ADR 005 (PCTC)
**Status:** REMOVIDO via ADR 006. Funcionalidades consideradas desnecess√°rias para o novo motor.

---

---

## ‚öôÔ∏è Especifica√ß√µes T√©cnicas Cr√≠ticas (V3.0)

### 1. Depend√™ncias e Compatibilidade
*   **Diffusers**: `>0.27.0` (Obrigat√≥rio para `ip_adapter_masks`). Vers√µes anteriores causam `TypeError`.
*   **PyTorch**: `>2.0.0` (Recomendado para otimiza√ß√µes de mem√≥ria).
*   **VRAM**: 
    *   **M√≠nimo**: 8GB (Single Reference).
    *   **Recomendado**: 12GB (Dual Reference + Regional).
    *   **Limite**: 2 Refer√™ncias simult√¢neas por tile em 12GB. Acima disso, o sistema ativa fallback sequencial.
*   **Disk Space**: ~5.5GB (SD 1.5: 4GB, ControlNet: 723MB, IP-Adapter: 400MB).

### 2. Formato de Dados
*   **M√°scaras IP-Adapter**:
    *   **Dimens√£o**: 64x64 (Latent Space do SD 1.5).
    *   **Tipo**: `torch.float32` (Suavizadas, range 0.0-1.0).
    *   **Redimensionamento**: O engine redimensiona m√°scaras 512x512 automaticamente usando `Image.NEAREST`.
*   **Imagens de Refer√™ncia**:
    *   **Resolu√ß√£o Ideal**: 224x224 (CLIP padr√£o) ou 512x512.
    *   **Aspect Ratio**: Quadrada (1:1). Imagens retangulares sofrem squeeze/distortion.
    *   **Conte√∫do**: Close-up de rosto (ArcFace) + Torso superior (CLIP/IP-Adapter) para melhor fidelidade.

### 3. Pipeline Gr√°fico e Determinismo
*   **Seed**: O sistema √© determin√≠stico se `seed` for fornecido. O `SD15LineartEngine` instancia `torch.Generator("cpu").manual_seed(seed)` para garantir reprodutibilidade.
*   **Ordem de Composi√ß√£o**:
    1.  **Gera√ß√£o**: SD 1.5 + Lineart + IP-Adapter -> RGB (Base Color).
    2.  **Multiply Blend**: `Base Color * Original Lineart` -> Preserva pretos absolutos.
    3.  **Text Compositing**: Restaura√ß√£o de bal√µes (Original) sobre a imagem colorida.
*   **Lineart Preprocessing**:
    *   O engine **inverte automaticamente** imagens de mang√° (Preto no Branco) para o formato esperado pelo ControlNet (Branco no Preto) se a m√©dia de brilho for > 127.

### 4. Limites e Escalabilidade
*   **Personagens por Cap√≠tulo**: Limitado pela mem√≥ria RAM no Clustering (FAISS). 
    *   **Threshold de Merge Identity**: 0.95 (Cosine Similarity).
    *   **Edge Case**: Personagens sem rosto/costas dependem puramente do pipeline `ScenePalette` (Prompt Injection).
*   **Persist√™ncia**:
    *   `scene_palette.json`: Salvo em `output/debug/` (V3 Debug) ou diret√≥rio do cap√≠tulo.
    *   Cache de Embeddings: `data/cache/*.npy`.

### 5. Defensive Engineering & Adapters
*   **VAEDtypeAdapter** (`core/generation/engines/vae_dtype_adapter.py`):
    *   **Problema**: Em ambientes Windows + CUDA + SD 1.5 (FP16 Pipeline), o VAE (FP32) falha com `RuntimeError: Input type (struct c10::Half) and bias type (float) should be the same` durante o decode, mesmo com `vae.config.force_upcast=True` (bug/limita√ß√£o de vers√µes espec√≠ficas do diffusers/torch).
    *   **Solu√ß√£o**: Wrapper implementado via Context Manager que intercepta a chamada `vae.decode`.
    *   **Mecanismo**: Verifica se os latents de entrada est√£o no mesmo dtype do VAE. Se n√£o, realiza cast expl√≠cito (`latents.to(vae.dtype)`) antes de prosseguir.
    *   **Uso**: O `SD15LineartEngine` envolve a chamada de gera√ß√£o com `with VAEDtypeAdapter(self.pipe.vae):`. Isso isola o "fix" e evita monkey patching global destrutivo.

---


---

*Documento atualizado em: 14/02/2026 (v3.0.1 + Bubble Masking + AVQV)*
