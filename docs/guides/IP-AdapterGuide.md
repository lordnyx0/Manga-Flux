# Guia T√©cnico: Regional IP-Adapter com Early-Heavy Injection para MangaAutoColor Pro

> **Documento T√©cnico Revisado - Arquitetura Simplificada**
> 
> **Vers√£o:** 2.0  
> **Data:** 2026-02-05  
> **Projeto:** MangaAutoColor Pro v2.5  
> **Status:** CORRE√á√ÉO DE ARQUITETURA - Usar API nativa do Diffusers

---

## üìã √çndice

1. [Descobertas Cient√≠ficas](#descobertas-cient√≠ficas)
2. [Corre√ß√£o de Arquitetura](#corre√ß√£o-de-arquitetura)
3. [Especifica√ß√£o T√©cnica](#especifica√ß√£o-t√©cnica)
4. [Algoritmo de Early-Heavy Injection](#algoritmo-de-early-heavy-injection)
5. [Integra√ß√£o com Pipeline](#integra√ß√£o-com-pipeline-existente)
6. [Gest√£o de VRAM](#gest√£o-de-vram)
7. [Checklist de Implementa√ß√£o](#checklist-de-implementa√ß√£o)
8. [Refer√™ncias](#refer√™ncias)

---

## Descobertas Cient√≠ficas

### 1.1 O Paradigma da Inje√ß√£o Temporal (T-GATE - ICML 2024)

Pesquisa publicada no ICML 2024 demonstra que **cross-attention √© necess√°ria apenas nos primeiros 20% dos steps** (etapa de "semantics-planning"). Nos 80% finais ("fidelity-improving"), a inje√ß√£o cont√≠nua √© redundante e pode prejudicar a fidelidade estrutural.

**Implica√ß√£o para SDXL-Lightning (4 steps):**

| Step | Porcentagem | Fase | Estrat√©gia IP-Adapter |
|------|-------------|------|----------------------|
| 0 | 0-25% | Semantics-Planning | **M√°xima for√ßa** (scale 1.0) - Define "quem" √© o personagem |
| 1 | 25-50% | Transition | Redu√ß√£o (scale 0.6) ou altern√¢ncia c√≠clica |
| 2 | 50-75% | Fidelity-Improving | **Desligado** (scale 0.0) - ControlNet domina |
| 3 | 75-100% | Refinement | **Desligado** (scale 0.0) - Finaliza√ß√£o sem interfer√™ncia |

### 1.2 Multi-Embedding C√≠clico vs Simult√¢neo (ICAS 2025)

Estudos quantitativos mostram que injetar m√∫ltiplos embeddings **simultaneamente** (scale [0.5, 0.5]) causa:
- "Oversimplification" (simplifica√ß√£o excessiva)
- Vazamento de identidade entre personagens

A estrat√©gia **c√≠clica** (alternar foco por step) preserva **40% mais caracter√≠sticas individuais** em cen√°rios multi-subject.

---

## Corre√ß√£o de Arquitetura

### ‚ùå N√ÉO Implementar (Estrat√©gia Anterior - Obsoleta)

```python
# N√ÉO CRIAR ESTA CLASSE - Reinventa a roda
class RegionalIPAdapterXL:
    def _modify_unet_attention(self): 
        # Monkey-patching desnecess√°rio e arriscado
        ...
```

**Problemas da abordagem anterior:**
- Monkey-patching do UNet √© inst√°vel
- Manuten√ß√£o complexa com updates do Diffusers
- Reimplementa funcionalidade que j√° existe nativamente

### ‚úÖ Implementar (Estrat√©gia Baseada em Evid√™ncias)

Usar **API nativa do Diffusers ‚â•0.29.0** com `cross_attention_kwargs` e callback de otimiza√ß√£o temporal:

```python
from diffusers.image_processor import IPAdapterMaskProcessor
from diffusers import StableDiffusionXLControlNetPipeline
```

**Vantagens:**
- ‚úÖ C√≥digo mantido pela HuggingFace
- ‚úÖ Testado e otimizado
- ‚úÖ Compat√≠vel com futuras vers√µes
- ‚úÖ Menos bugs, mais performance

---

## Especifica√ß√£o T√©cnica

### 2.1 Depend√™ncias

```bash
# requirements.txt - ATUALIZAR

diffusers>=0.29.0       # Necess√°rio para ip_adapter_masks
accelerate>=0.20.0      # Para cpu_offload
torch>=2.0.0
```

### 2.2 ‚ö†Ô∏è Avisos Importantes sobre IP-Adapter Plus Face ViT-H

#### O "Pegadinha" T√©cnica - Encoder ViT-H

O modelo **ip-adapter-plus-face_sdxl_vit-h** usa o encoder **CLIP-ViT-H-14**, que √© diferente do encoder padr√£o do SDXL (ViT-L-14).

> ‚ö†Ô∏è **Importante:** A biblioteca Diffusers moderna (‚â•0.29.0) baixa o encoder correto **automaticamente** quando voc√™ usa `load_ip_adapter()` apontando para `h94/IP-Adapter`. N√£o √© necess√°rio configura√ß√£o manual.

#### üé® Ajuste Fino para Mang√° (Anime vs Realismo)

O **Plus Face** foi treinado principalmente em **fotos de rostos humanos reais**. Quando aplicado em mang√° (desenho 2D), pode criar o efeito **"Uncanny Valley"**:

> Rosto 3D realista em corpo 2D de anime = estranho e inconsistente

**Recomenda√ß√µes de Scale para Mang√°:**

| Scale | Efeito | Recomenda√ß√£o |
|-------|--------|--------------|
| **0.5 - 0.7** | ‚úÖ **Ponto Ideal** | Captura identidade sem estragar tra√ßo 2D |
| **0.8 - 1.0** | ‚ö†Ô∏è Risco | Rosto come√ßa a parecer foto colada |
| **> 1.0** | ‚ùå Evitar | Efeito 3D forte, inconsistente com mang√° |

**Nossa Estrat√©gia Early-Heavy:**
- **Step 0:** Scale 1.0 (apenas neste momento cr√≠tico de sem√¢ntica)
- **Step 1:** Scale 0.6 (fade)
- **Steps 2-3:** Scale 0.0 (desligado)

Isso garante que o personagem seja reconhecido sem que o estilo 2D seja corrompido.

#### üíæ Gest√£o de VRAM - ViT-H √© Grande!

O encoder ViT-H consome aproximadamente **+600MB de VRAM** adicional:

```
SDXL-Lightning Base:        ~6.0 GB
+ ControlNet Canny:         +2.0 GB
+ IP-Adapter Plus ViT-H:    +0.6 GB
+ Buffers e m√°scaras:       +0.3 GB
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Total Estimado:             ~8.9 GB
Margem Seguran√ßa (12GB):    ~3.1 GB ‚úÖ
```

> ‚ö†Ô∏è **OBRIGAT√ìRIO:** Usar `enable_model_cpu_offload()` na RTX 3060 12GB!

---

### 2.3 Novo M√≥dulo: `core/generation/regional_ip_adapter.py`

### 2.2 Novo M√≥dulo: `core/generation/regional_ip_adapter.py`

```python
"""
Regional IP-Adapter com Early-Heavy Injection para SDXL-Lightning 4-Step.

Baseado em:
- T-GATE (ICML 2024): Early stopping de cross-attention em few-steps models
- ICAS (2025): Multi-embedding cyclic injection superior a simultaneous
"""

import torch
import numpy as np
from typing import List, Dict, Optional, Tuple
from PIL import Image
from dataclasses import dataclass
from diffusers.image_processor import IPAdapterMaskProcessor


@dataclass
class RegionalCharacter:
    """
    Estrutura de dados para personagem regional.
    
    Args:
        char_id: Identificador √∫nico do personagem
        embedding: Tensor CLIP do personagem (do HybridIdentitySystem)
        mask: Array numpy (H, W) com valores 0.0-1.0
        crop_image: PIL Image do crop do personagem (para IP-Adapter)
    """
    char_id: str
    embedding: torch.Tensor
    mask: np.ndarray
    crop_image: Image.Image


class EarlyHeavyRegionalIP:
    """
    Controlador de IP-Adapter com otimiza√ß√£o temporal para 4 steps.
    
    Implementa a estrat√©gia Early-Heavy baseada em T-GATE:
    - Steps 0-1: Inje√ß√£o m√°xima (semantics planning)
    - Steps 2-3: Desligado (fidelity improvement sem interfer√™ncia)
    
    Para m√∫ltiplos personagens, usa inje√ß√£o c√≠clica (ICAS):
    - Step 0: Personagem A com for√ßa m√°xima
    - Step 1: Personagem B com for√ßa m√°xima (ou fade se √∫nico)
    - Steps 2-3: Desligado para todos
    """
    
    def __init__(
        self,
        pipeline,  # StableDiffusionXLControlNetPipeline
        device: str = "cuda",
        dtype: torch.dtype = torch.float16
    ):
        self.pipeline = pipeline
        self.device = device
        self.dtype = dtype
        self.mask_processor = IPAdapterMaskProcessor()
        
        # Carregar IP-Adapter Plus Face ViT-H (maior impacto por step)
        # ‚ö†Ô∏è IMPORTANTE: Este modelo usa encoder ViT-H, n√£o o padr√£o do SDXL
        # A API moderna do Diffusers baixa o encoder correto automaticamente
        self.pipeline.load_ip_adapter(
            "h94/IP-Adapter",
            subfolder="sdxl_models",
            weight_name="ip-adapter-plus-face_sdxl_vit-h.safetensors",
            torch_dtype=dtype
        )
        
        # üé® AJUSTE FINO PARA MANG√Å:
        # O plus-face tende a realismo. Em mang√°, pode criar "Uncanny Valley"
        # (rosto 3D em corpo 2D). Mantenha scale baixo!
        # 
        # Recomenda√ß√µes para mang√°:
        # - 0.5 a 0.7: Ponto ideal (captura identidade sem estragar tra√ßo 2D)
        # - > 0.8: Risco de rosto parecer foto colada (evitar!)
        # - Early-Heavy usa 1.0 apenas no Step 0 (semantics), depois reduz
        
        # Otimiza√ß√µes de VRAM obrigat√≥rias para RTX 3060 12GB
        self.pipeline.enable_model_cpu_offload()
        self.pipeline.enable_vae_slicing()
    
    def generate_regional(
        self,
        prompt: str,
        negative_prompt: str = "",
        characters: Optional[List[RegionalCharacter]] = None,
        controlnet_image: Optional[Image.Image] = None,
        num_inference_steps: int = 4,  # FIXO - SDXL-Lightning
        guidance_scale: float = 1.2,
        height: int = 1024,
        width: int = 1408,
    ) -> Image.Image:
        """
        Gera imagem com IP-Adapter regional otimizado para 4 steps.
        
        Args:
            prompt: Prompt de texto
            negative_prompt: Prompt negativo
            characters: Lista de RegionalCharacter (m√°ximo 2 para RTX 3060 12GB)
            controlnet_image: Imagem Canny para ControlNet
            num_inference_steps: Deve ser 4 (SDXL-Lightning)
            guidance_scale: Scale do CFG (1.2 para Lightning)
            height: Altura da imagem
            width: Largura da imagem
            
        Returns:
            Imagem PIL gerada
            
        Raises:
            ValueError: Se mais de 2 personagens (limita√ß√£o de VRAM)
        """
        if not characters:
            return self._generate_base(prompt, negative_prompt, controlnet_image)
        
        if len(characters) > 2:
            raise ValueError(
                "RTX 3060 12GB suporta m√°ximo 2 personagens simult√¢neos "
                "sem OOM. Use batching sequencial para 3+ personagens."
            )
        
        # 1. Preparar imagens de refer√™ncia (crops dos personagens)
        reference_images = [char.crop_image for char in characters]
        
        # 2. Preparar m√°scaras regionais
        masks = [char.mask for char in characters]
        processed_masks = self.mask_processor.preprocess(
            masks, height=height, width=width
        )
        
        # Reshape para formato esperado: (batch_size, num_images, H, W)
        ip_adapter_masks = processed_masks.reshape(
            1, len(characters), processed_masks.shape[-2], processed_masks.shape[-1]
        )
        
        # 3. Configurar escala inicial (ser√° modificada pelo callback)
        # Formato: [[scale_char1, scale_char2, ...]]
        num_chars = len(characters)
        
        # 4. Callback de Early-Heavy Injection (Fundamentado em T-GATE)
        def early_heavy_callback(pipe, step_index, timestep, callback_kwargs):
            """
            Estrat√©gia de inje√ß√£o temporal otimizada.
            
            Para 2 personagens (c√≠clica):
            - Step 0: [1.0, 0.0] - Personagem A "carimba" identidade
            - Step 1: [0.0, 1.0] - Personagem B "carimba" identidade
            - Steps 2-3: [0.0, 0.0] - Desligado, ControlNet domina
            
            Para 1 personagem:
            - Step 0: [1.0] - M√°xima for√ßa
            - Step 1: [0.6] - Fade
            - Steps 2-3: [0.0] - Desligado
            """
            if step_index == 0:
                # Semantics planning: m√°xima for√ßa no primeiro personagem
                scales = [[1.0 if i == 0 else 0.0 for i in range(num_chars)]]
            elif step_index == 1:
                if num_chars > 1:
                    # Altern√¢ncia c√≠clica para segundo personagem
                    scales = [[0.0 if i == 0 else 1.0 for i in range(num_chars)]]
                else:
                    # Fade para personagem √∫nico
                    scales = [[0.6]]
            else:
                # Fidelity improving: desliga IP-Adapter
                # Permite que ControlNet refine estrutura sem conflito
                scales = [[0.0 for _ in range(num_chars)]]
            
            pipe.set_ip_adapter_scale(scales)
            return callback_kwargs
        
        # 5. Executar gera√ß√£o
        result = self.pipeline(
            prompt=prompt,
            negative_prompt=negative_prompt,
            image=controlnet_image,
            ip_adapter_image=reference_images,
            cross_attention_kwargs={"ip_adapter_masks": ip_adapter_masks},
            num_inference_steps=num_inference_steps,
            guidance_scale=guidance_scale,
            height=height,
            width=width,
            callback_on_step_end=early_heavy_callback,
        ).images[0]
        
        return result
    
    def _generate_base(
        self,
        prompt: str,
        negative_prompt: str,
        controlnet_image: Optional[Image.Image]
    ) -> Image.Image:
        """Fallback sem IP-Adapter quando n√£o h√° personagens conhecidos."""
        return self.pipeline(
            prompt=prompt,
            negative_prompt=negative_prompt,
            image=controlnet_image,
            num_inference_steps=4,
            guidance_scale=1.2,
        ).images[0]
```

---

## Algoritmo de Early-Heavy Injection

### 3.1 Por que Funciona em 4 Steps?

Baseado em T-GATE, o processo de difus√£o tem duas fases distintas:

```
Step 0 (0-25%): SEMANTICS-PLANNING
‚îú‚îÄ‚îÄ O latent √© puro ru√≠do gaussiano
‚îú‚îÄ‚îÄ Cross-attention define a "dire√ß√£o" sem√¢ntica
‚îî‚îÄ‚îÄ IP-Adapter deve ter m√°xima influ√™ncia (scale 1.0)

Step 1 (25-50%): TRANSITION  
‚îú‚îÄ‚îÄ Latent organiza estrutura b√°sica
‚îú‚îÄ‚îÄ IP-Adapter mant√©m identidade mas cede para ControlNet
‚îî‚îÄ‚îÄ Scale reduzido (0.6) ou altern√¢ncia c√≠clica

Steps 2-3 (50-100%): FIDELITY-IMPROVING
‚îú‚îÄ‚îÄ Estrutura j√° est√° definida (anatomia, pose)
‚îú‚îÄ‚îÄ Cross-attention adicional introduz ru√≠do/artefatos
‚îú‚îÄ‚îÄ ControlNet deve dominar (preservar bordas Canny)
‚îî‚îÄ‚îÄ IP-Adapter deve ser 0.0 para n√£o competir
```

### 3.2 Estrat√©gia C√≠clica para 2 Personagens

**Problema com abordagem simult√¢nea:**
```python
# ‚ùå RUIM: Ambos simult√¢neos causam vazamento
scales = [0.5, 0.5]  # Constante - oversimplification
```

**Solu√ß√£o com inje√ß√£o c√≠clica:**
```python
# ‚úÖ BOM: Altern√¢ncia exclusiva preserva identidade
Step 0: [1.0, 0.0]  # A "carimba" identidade no latent
Step 1: [0.0, 1.0]  # B "carimba" identidade no latent  
Step 2: [0.0, 0.0]  # Refinamento estrutural puro
Step 3: [0.0, 0.0]  # Finaliza√ß√£o sem interfer√™ncia
```

**Resultado:** Cada personagem recebe aten√ß√£o exclusiva durante o momento cr√≠tico, eliminando competi√ß√£o por cross-attention.

---

## Integra√ß√£o com Pipeline Existente

### 4.1 Modifica√ß√µes em `core/generation/pipeline.py`

```python
def _generate_single_tile(
    self,
    image: Image.Image,
    canny_edges: np.ndarray,
    character_embeddings: Dict[str, torch.Tensor],
    detections: List[Dict],
    options: Any,
    original_image: Optional[Image.Image] = None,
    target_size: Optional[Tuple[int, int]] = None,
    character_masks: Optional[Dict[str, np.ndarray]] = None,  # NOVO
    character_crops: Optional[Dict[str, Image.Image]] = None,  # NOVO
) -> Image.Image:
    """
    Gera tile √∫nico com suporte a Regional IP-Adapter.
    """
    # ... c√≥digo existente ...
    
    # Verificar se Regional IP-Adapter est√° dispon√≠vel e necess√°rio
    has_regional_data = (
        character_masks is not None and 
        character_crops is not None and
        len(character_embeddings) > 0
    )
    
    if has_regional_data and REGIONAL_IP_AVAILABLE:
        # Preparar RegionalCharacters
        characters = []
        for idx, (char_id, embedding) in enumerate(character_embeddings.items()):
            if idx >= 2:  # Limita√ß√£o VRAM
                break
            
            mask = character_masks.get(char_id)
            crop = character_crops.get(char_id)
            
            if mask is not None and crop is not None:
                characters.append(RegionalCharacter(
                    char_id=char_id,
                    embedding=embedding,
                    mask=mask,
                    crop_image=crop
                ))
        
        # Inicializar controller (lazy singleton)
        if not hasattr(self, '_regional_ip_controller'):
            from .regional_ip_adapter import EarlyHeavyRegionalIP
            self._regional_ip_controller = EarlyHeavyRegionalIP(
                pipeline=self.pipeline,
                device=self.device,
                dtype=self.dtype
            )
        
        # Gerar com Regional IP-Adapter
        result = self._regional_ip_controller.generate_regional(
            prompt=prompt,
            negative_prompt=negative_prompt,
            characters=characters,
            controlnet_image=canny_pil,
            height=image.height,
            width=image.width
        )
    else:
        # Fallback para gera√ß√£o base (sem IP-Adapter ou vers√£o antiga)
        result = self._generate_with_standard_pipeline(...)
    
    return result
```

### 4.2 Modifica√ß√µes em `core/chapter_processing/pass2_generator.py`

```python
def _generate_single_tile_page(self, ...):
    # Carregar dados existentes...
    active_embeddings = {...}
    masks = {...}
    
    # NOVO: Carregar crops dos personagens para IP-Adapter
    character_crops = {}
    for char_id in tile_job.active_char_ids:
        # Carregar crop do personagem (salvo no Pass 1)
        crop_path = self.db.get_character_crop_path(char_id)
        if crop_path:
            character_crops[char_id] = Image.open(crop_path).convert('RGB')
    
    # Adicionar √†s op√ß√µes
    options_with_masks['character_crops'] = character_crops
    
    result = self.generator.generate_image(...)
```

---

## Gest√£o de VRAM

### 5.1 Profile de Mem√≥ria

```
Base (SDXL-Lightning + ControlNet):         ~8.2 GB
+ IP-Adapter Plus Face (1 personagem):      +0.4 GB
+ IP-Adapter Plus Face (2 personagens):     +0.8 GB
+ M√°scaras e buffers tempor√°rios:           +0.3 GB
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
TOTAL ESTIMADO:                             ~9.3 GB
Margem de seguran√ßa (12GB - 9.3GB):         ~2.7 GB ‚úÖ
```

### 5.2 Otimiza√ß√µes Obrigat√≥rias

```python
# No __init__ do EarlyHeavyRegionalIP
self.pipeline.enable_model_cpu_offload()  # Essencial para 2 personagens
self.pipeline.enable_vae_slicing()        # Para tiles grandes

# Durante gera√ß√£o de m√∫ltiplas p√°ginas
torch.cuda.empty_cache()  # Entre p√°ginas
```

### 5.3 Fallback de Mem√≥ria

```python
try:
    result = self.generate_regional(characters=[char1, char2], ...)
except torch.cuda.OutOfMemoryError:
    torch.cuda.empty_cache()
    # Fallback: Gerar um por vez
    result = self._generate_sequential(characters)
```

---

## Checklist de Implementa√ß√£o

### Fase 1: Setup (Dia 1)
- [ ] Atualizar `requirements.txt` para `diffusers>=0.29.0`
- [ ] Criar `core/generation/regional_ip_adapter.py`
- [ ] Baixar modelo `ip-adapter-plus-face_sdxl_vit-h.safetensors`

### Fase 2: Integra√ß√£o (Dia 2)
- [ ] Modificar `core/generation/pipeline.py`
- [ ] Adaptar `Pass2Generator` para fornecer crops dos personagens
- [ ] Garantir que m√°scaras sejam salvas em formato (H, W) float32

### Fase 3: Testes (Dia 3)
- [ ] **Teste A/B:** Early-Heavy vs Scale constante (medir qualidade)
- [ ] **Teste de Isolamento:** Dois personagens distintos - verificar vazamento
- [ ] **Teste de VRAM:** Monitorar `nvidia-smi` com 2 personagens em 1024x1024
- [ ] **Teste de Consist√™ncia:** Mesmo personagem em 3 p√°ginas - Delta E < 5.0

### Fase 4: Otimiza√ß√£o (Dia 4)
- [ ] Cache de embeddings em mem√≥ria
- [ ] Ajustar sigma do gaussian blur nas m√°scaras (testar 5.0, 10.0, 20.0)
- [ ] Fine-tuning do scale inicial (0.9 vs 1.0 vs 1.1)

---

## Refer√™ncias

### Papers Cient√≠ficos

1. **T-GATE (ICML 2024)**: "Cross-Attention Makes Inference Cumbersome in Text-to-Image Diffusion Models"
   - Zhang et al.
   - Early stopping de cross-attention em few-steps models

2. **ICAS (2025)**: "IP-Adapter and ControlNet-based Attention Structure"
   - Yang et al.
   - Multi-embedding cyclic injection vs simultaneous

### Documenta√ß√£o T√©cnica

3. **HuggingFace Diffusers ‚â•0.29.0**: 
   - `IPAdapterMaskProcessor`
   - `cross_attention_kwargs` com `ip_adapter_masks`
   - Documenta√ß√£o: https://huggingface.co/docs/diffusers

### Reposit√≥rios

4. **IP-Adapter**: https://github.com/tencent-ailab/IP-Adapter
5. **MangaAutoColor Pro**: `docs/ARCHITECTURE.md`

---

## Notas Finais

> **"N√£o reinvente a roda implementando camadas de aten√ß√£o customizadas. A API nativa do Diffusers j√° possui o mecanismo de regional masking. Foque na estrat√©gia temporal de inje√ß√£o (Early-Heavy), que √© onde reside o ganho de qualidade em 4 steps."**

### Pr√≥ximos Passos

1. Implementar m√≥dulo `EarlyHeavyRegionalIP`
2. Integrar com pipeline existente mantendo backward compatibility
3. Testar rigorosamente com diferentes cen√°rios de personagens
4. Documentar resultados e m√©tricas de qualidade

---

<p align="center">
  <strong>Documento T√©cnico Revisado v2.0</strong><br>
  MangaAutoColor Pro - Implementa√ß√£o Regional IP-Adapter com Early-Heavy Injection<br>
  2026
</p>
