# Fase B: Implementa√ß√£o Real do Pass2 (Manga-Flux)

Este documento estabelece o escopo, arquitetura e os checklists da **Fase B** do projeto: a substitui√ß√£o do mock/dummy do Pass2 pelo uso real dos modelos de difus√£o (j√° presentes no diret√≥rio `/models`).

## 1. Vis√£o Arquitetural e Fluxo (Pass1 -> Pass2 -> API -> Extension)

Para garantir que a integra√ß√£o real flua perfeitamente, o fluxo entre os componentes foi unificado:

```mermaid
sequenceDiagram
    participant Ext as Chrome Extension
    participant API as Local API (server.py)
    participant P1 as Pass1 Pipeline
    participant FAISS as FAISS Semantic Search
    participant P2O as Pass2 Orchestrator
    participant P2E as Diffusion Engine (Flux)

    Ext->>API: POST /v1/pipeline/run_chapter (Images/URLs)
    API->>P1: Inicia processamento de An√°lise
    P1->>P1: Extrai M√°scaras, Segmenta√ß√µes, YOLO
    P1->>FAISS: Busca refer√™ncia sem√¢ntica (Opcional)
    FAISS-->>P1: Retorna embeddings/estilos
    P1-->>API: Salva metadata JSON + Masks no disco
    
    API->>P2O: Inicia Pass2
    P2O->>P2O: PromptBuilder / MaskBinder / StyleBinder
    P2O->>P2E: Envia Payload Formatado para Infer√™ncia
    Note over P2E: Inference c/ VRAM Offload (Flux)
    P2E-->>P2O: Retorna tensores gerados
    P2O-->>API: Salva Imagens Colorizadas + Runmeta no disco
    API-->>Ext: Retorna status/Caminhos das imagens
```

### Detalhamento do Fluxo
1. **Extension**: A extens√£o atua como o ve√≠culo de orquestra√ß√£o do leitor. Suas duas fun√ß√µes principais s√£o:
    - **Capturar a P√°gina Alvo:** Captura ativamente a p√°gina de mang√° que o usu√°rio est√° lendo no site alvo.
    - **Capturar a Refer√™ncia:** Fornecer e anexar a imagem de "Style Reference", que cont√©m os personagens e o estilo de coloriza√ß√£o que guiar√£o a gera√ß√£o. Ela empacota essas imagens/URLs e dispara as chamadas em lote (`POST /v1/pipeline/run_chapter` ou `batch`) para a API local.
2. **API**: Valida a requisi√ß√£o, as credenciais e encaminha os dados de imagem/estado para a camada de processamento de pipelines.
3. **Pass1**: Analisa as imagens brutas usando o YOLO e algoritmos de segmenta√ß√£o para achar bal√µes e personagens, gerando as matrizes de contexto (m√°scaras e z-buffer) na forma de contratos `meta.json`.
4. **FAISS Retrieval (Pr√©-Gera√ß√£o)**: A busca sem√¢ntica acontece *ap√≥s* a extra√ß√£o do Pass1, mas *antes* do Pass2. As refer√™ncias s√£o adicionadas ao `meta.json`.
5. **Pass2 Orchestrator**: Para evitar que a Engine colapse fazendo o binding do metadata junto com a infer√™ncia, a arquitetura foi desmembrada em camadas:
    - **PromptBuilder**: L√™ o JSON e monta os condicionamentos textuais (ex: descreve que no painel 1 h√° o "Personagem X", formatando a prompt que guiar√° o Flux).
    - **MaskBinder**: Determina exatamente para que as m√°scaras serviment√£o na estrat√©gia de gera√ß√£o (inicialmente: preserva√ß√£o de bal√µes/texto para evitar que a rede mexa nessa √°rea).
    - **StyleBinder**: Prepara os embeddings ou imagens de estilo (IP-Adapter/refer√™ncia). **Nota sobre Viabilidade no Flux:** Na Fase B inicial, a refer√™ncia de estilo atua de forma *global* (color palette e tra√ßos gerais do personagem injetados via IP-Adapter/Image Prompt). Um "link" espacial perfeito (personagem X da ref -> bounding box Y do mang√°) via difus√£o pura exige arquiteturas multi-adapter complexas. Inicialmente, confiaremos no `PromptBuilder` para o posicionamento de texto e na refer√™ncia de estilo global para o look, estabilizando isso antes de tentar refer√™ncias contextuais por m√°scara regional.
6. **DiffusionEngine (Agn√≥stica / Plug & Play)**: O papel da Engine (atualmente `FluxEngine`) √© puramente de infer√™ncia. Ela recebe o payload padr√£o criado pelo Orchestrator e aplica t√©cnicas de offload e infer√™ncia. **A substitui√ß√£o do motor:** Gra√ßas a essa barreira arquitetural imposta pelo Orchestrator, se no futuro o modelo mudar (ex: ado√ß√£o do *Qwen 3* ou outra SOTA de difus√£o), apenas o componente final (`QwenEngine.py`, etc) precisa ser escrito, absorvendo as vari√°veis do Orchestrator, sem quebrar os processos do Pass1, API, JSON ou Extension.

## 2. Plano de Implementa√ß√£o da Fase B (Checklist)

Este checklist ser√° **constantemente atualizado** durante a integra√ß√£o do Pass2 real.

### 2.1. Prepara√ß√£o da Infraestrutura de Infer√™ncia
- [x] Mapear todos os modelos necess√°rios de `/models` (Base Model, VAE, ControlNet, LoRAs).
- [x] Configurar os paths absolutos/relativos corretos no `core/config.py` ou `constants.py` apontando para `/models`.
- [ ] Garantir que depend√™ncias de infer√™ncia profunda (`diffusers`, `transformers`, `torch` com CUDA, etc.) existam e funcionem no env local.

### 2.2. Estrat√©gia Inicial e Valida√ß√£o da API do Modelo
Antes de projetar o pipeline completo, √© crucial confirmar o comportamento do modelo *Flux* com a biblioteca Diffusers.
- [x] Confirmar pipeline prim√°rio: Testar o carregamento b√°sico usando `DiffusionPipeline.from_pretrained(...)`.
- [x] **Teste de Sanidade de API:** Escrever um script que valide o Flux com `enable_model_cpu_offload()` rodando um `image = pipe(prompt, image=img, strength=1.0)` b√°sico sem OOM.
- [x] **Estrat√©gia de Gera√ß√£o (Fase B Inicial):** Implementar **Img2Img Full-Frame com preserva√ß√£o de m√°scara de texto**. N√£o usar Inpainting regional complexo nesta fase inicial.

> **üí° Alerta de Viabilidade (GGUF vs Diffusers):**
> Durante os testes de sanidade, detectou-se que a biblioteca `diffusers` padr√£o **n√£o suporta carregamento nativo de pesos GGUF** do Flux (`flux-2-klein-9b-Q4_K_M.gguf`). A HuggingFace exige formato `safetensors` ou diret√≥rios HuggingFace Hub para carregar nativamente.
> **Impacto no Plano Resolvido (Op√ß√£o B Escolhida):** Como a vers√£o GGUF quantizada reduz a necessidade de offload extremo mas n√£o √© suportada nativamente em Python, **adotamos a Op√ß√£o B (ComfyUI Headless)**. A `FluxEngine` (no Manga-Flux) atuar√° como um cliente REST que monta um workflow JSON e o despacha para uma inst√¢ncia do ComfyUI rodando localmente em background.
> 
> **üî§ Nota sobre Codificador de Texto (Flux.2 Klein + Qwen3):**
> A s√©rie **Flux.2 Klein** abandonou a estrutura bimodal original do Flux.1 (T5-XXL + CLIP-L) e utiliza estritamente o modelo de linguagem **Qwen 3** para Text Encoding. O n√≥ `CLIPLoader` dentro da Payload JSON deve sempre apontar para `qwen_3_8b_fp4mixed.safetensors`.

### 2.3. Implementa√ß√£o da Arquitetura do Pass2 (Orchestrator e Engine ComfyUI)
- [x] Implementar a separa√ß√£o em camadas (`Pass2 Orchestrator` -> `PromptBuilder`, `MaskBinder`, `StyleBinder`, `FluxEngine` via REST).
- [x] Implementar cliente em `core/generation/engines/flux_engine.py` para converter o Payload Agn√≥stico num "ComfyUI API Workflow JSON".
- [x] Definir o papel claro do **MaskBinder**: As m√°scaras na Fase B inicial ser√£o usadas primariamente para **preservar os textos/bal√µes originais** e evitar over-generation nessas √°reas durante o Img2Img Full-Frame.
- [x] **Integra√ß√£o Node ComfyUI:** Garantir que o Workflow JSON submetido possua compatibilidade com os custom nodes para GGUF (ex: `UnetLoaderGGUF`).
- [x] Executar primeira rota visual de ponta a ponta (Pass1 -> JSON -> Orchestrator -> ComfyUI JSON Payload -> Gera√ß√£o -> Retorno).

> **‚ö†Ô∏è Alerta T√©cnico (Descobertas Sobre Coloriza√ß√£o Img2Img no FLUX):**
> Durante os testes de integra√ß√£o do modelo `FLUX.2-Klein` em conjunto com o estilo LoRA `colorMangaKlein`, deparamo-nos com limita√ß√µes profundas do comportamento Flow Matching da base FLUX usando `img2img` tradicional (VAEEncode -> KSampler):
> 1. **Sensibilidade do Denoise:** No `KSampler` padr√£o, se o denoise for `> 0.6`, o FLUX alucina e come√ßa a gerar textos e bal√µes em alien√≠gena, ignorando completamente o tra√ßo original (destrui√ß√£o do contexto). Se o denoise for `< 0.5`, ele respeita o contexto "demais", n√£o colorindo absolutamente nada e devolvendo uma imagem em preto e branco.
> 2. **Incompatibilidade EPS:** Tentar colocar o node `ModelSamplingDiscrete` em formato padr√£o `eps` causa a quebra matem√°tica completa dos tensores latentes do FLUX (gerando ru√≠dos de TV), pois sua base n√£o mapeia ru√≠do convencional, mas sim um Flow Matching (Retificadores de Fluxo). A √∫nica curadora manual de amostragem poss√≠vel no base nodeset √© passar o modelo nativamente para o KSampler para ele extrair as configura√ß√µes do checkpoint.
> 3. **Workflow Proprietary Injection (UUID `4929e576-...`):** Ao analisar um Workflow em JSON validado visualmente funcional para coloriza√ß√£o, descobrimos que ele **n√£o utiliza** VAEEncode tradicional (Img2Img). A imagem n√£o passa no denoiser. Em vez disso, a pipeline gera um Empty Latent e a imagem lineart √© codificada e injetada via Conditioning (Text) juntamente com o prompt por meio de um Node Agrupado oculto de UUID `4929e576-3fd7-44d8-afdb-6b2f67305d15`. Como GroupNodes de outras inst√¢ncias mascaram seus n√≥s internos reais (ControlNets, Pix2Pix, InpaintConditioningCustom), a reprodu√ß√£o exata da API Headless depende de descobrir quais os n√≥s prim√°rios que a interface converteu para essa GroupNode.

### 2.4. Integra√ß√£o com Bateria de Testes / Batch
- [x] Atualizar script `run_pass2_local.py` permitindo chave `--engine flux` acessar adequadamente o pipeline real.
- [ ] Ajustar e rodar o pipeline atrav√©s de `run_two_pass_batch_local.py` gerando resultados reais (batch de 3 a 5 p√°ginas).
- [ ] Observar consist√™ncia visual nas imagens renderizadas usando sementes est√°ticas (`--pass2-seed-offset`).
- [ ] Revisar tempo de infer√™ncia (`duration_ms`) e garantir observabilidade.

### 2.5. Padroniza√ß√£o Formal do Runmeta JSON
O artefato `runmeta.json` deve possuir uma estrutura de metadados exata para n√£o perder a rastreabilidade:
- [ ] Implementar validador ou builder formal, garantindo chaves como:
```json
{
  "engine": "flux",
  "model_name": "...",
  "model_hash": "...",
  "seed": 12345,
  "guidance_scale": 7.5,
  "num_steps": 30,
  "width": 1280,
  "height": 1808,
  "duration_ms": 4235,
  "vram_peak_mb": 7420
}
```

### 2.6. Refinamento e Funcionalidades Avan√ßadas
- [ ] Gerenciamento/Logging de erros se a API do Pass2 falhar por falta de modelo ou OOM (`Out of Memory`).
- [ ] Implementar Integra√ß√£o FAISS **apenas na fase de extra√ß√£o (p√≥s Pass1)** alimentando o JSON. A busca sem√¢ntica n√£o far√° parte do ciclo de vida da CPU/GPU durante a engine de difus√£o.
- [ ] Retornar metadados ricos para a Extens√£o Chrome sobre os par√¢metros que a difus√£o real interpretou.

---

> **Nota:** Use os scripts em `scripts/` (como `validate_two_pass_outputs.py`) ap√≥s cada milestone visual para garantir que n√£o corrompemos o contrato do meta-json com a entrada do motor de IA.
