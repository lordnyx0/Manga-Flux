# Manga-Flux: The First Specialist Manga Colorization Engine (v1.0)

Manga-Flux Ã© um pipeline avanÃ§ado de colorizaÃ§Ã£o headless via API projetado com uma arquitetura **Two-Pass**:

- **Pass1 (AnÃ¡lise)**: IdentificaÃ§Ã£o e segmentaÃ§Ã£o estrutural (BalÃµes de texto, Rostos, Corpos, Quadros) usando IA de VisÃ£o (YOLO Manga109).
- **Pass2 (GeraÃ§Ã£o)**: ColorizaÃ§Ã£o de altÃ­ssima fidelidade utilizando a engine **FLUX.2-Klein**, guiado por metadados e injetando a Lineart diretamente no vetor de condicionamento textual (`ReferenceLatent`) para preservar 100% dos traÃ§os originais.

> **Status Atual:** (Fevereiro 2026) O projeto alcanÃ§ou um marco histÃ³rico. O Pass1 e o Pass2 estÃ£o integrados e operacionais. A arquitetura **ReferenceLatent** provou-se capaz de colorir perfeitamente preservando lineart sem a quebra do Denoise tradicional no Flux.
>
> **Problemas Conhecidos (A Caminho da Fase C):** 
> * **Cores Excessivas/Hiper-detalhamento:** A geraÃ§Ã£o atual resulta em cores muito vibrantes e com detalhes nÃ£o previstos.
> * **AlucinaÃ§Ãµes (Horror Vacui):** O modelo sofre para compor Ã¡reas de "vazio" (cÃ©u branco, fundos de balÃ£o mal lido), tendendo a desenhar objetos aleatÃ³rios onde deveria preservar o branco vazio. 
> * **ResoluÃ§Ã£o de Conflitos:** A Fase C (Desacoplada) estÃ¡ projetada para usar ComposiÃ§Ã£o Passiva e Inpaint Regional (guiado pelo Pass1) para corrigir e mascarar essas alucinaÃ§Ãµes.

## ğŸŒŸ Recursos Principais

- **FLUX Flow Matching Integration**: Usa tÃ©cnicas de `EmptyLatent` + `ReferenceLatent` customizadas para saltar limitaÃ§Ãµes de coloraÃ§Ã£o img2img no FLUX.
- **Smart Resolution Compositing**: Escalonamento bidirecional garante que seu mangÃ¡ em HD nÃ£o seja reduzido por limites de GPU, e que a colorizaÃ§Ã£o seja upscaled graciosamente para a montagem dos balÃµes.
- **Isolamento de Texto**: BalÃµes de fala limpos via detecÃ§Ã£o cirÃºrgica.

## ğŸ“¦ DependÃªncias NecessÃ¡rias

### Framework e MÃ³dulos Base
- `Python 3.10+`
- `onnxruntime-gpu` (ou `onnxruntime` para CPU) - Para inferÃªncia do YOLO no Pass1.
- `fastapi`, `uvicorn`, `requests`, `numpy`, `Pillow`

### ComfyUI Engine Backend
O Manga-Flux funciona interceptando uma instÃ¢ncia local do **ComfyUI** via API. VocÃª precisarÃ¡:
1. ComfyUI instalado localmente (https://github.com/comfyanonymous/ComfyUI)
2. Custom Node GGUF (`ComfyUI-GGUF`): `git clone https://github.com/city96/ComfyUI-GGUF`
3. Custom Node ReferenceLatent (`ComfyUI_experiments`): `git clone https://github.com/comfyanonymous/ComfyUI_experiments`

## ğŸ§  Modelos Utilizados (Baixe e insira nas respectivas pastas)

### YOLO / Pass1 (Manga Analysis)
*   **Manga109 YOLO ONNX**: `data/models/manga109_yolo.onnx`
    *   *Link*: [A ser adicionado]

### ComfyUI / Pass2 (Diffusion Generation)
*   **UNet (Base Model):** `flux-2-klein-9b-Q4_K_M.gguf` -> Coloque em `ComfyUI/models/unet/`
    *   *Link*: [A ser adicionado]
*   **LoRA (Style Injector):** `colorMangaKlein_9B.safetensors` -> Coloque em `ComfyUI/models/loras/`
    *   *Link*: [A ser adicionado]
*   **CLIP (Text Encoder):** `qwen_3_8b_fp4mixed.safetensors` -> Coloque em `ComfyUI/models/clip/`
    *   *Link*: [A ser adicionado]
*   **VAE:** `flux2-vae.safetensors` -> Coloque em `ComfyUI/models/vae/`
    *   *Link*: [A ser adicionado]

---

## ğŸ› ï¸ Executando o Pipeline

### Executar batch real local (Pass1->Pass2)

```bash
python run_two_pass_batch_local.py \
  --input-dir data/pages_bw \
  --style-reference data/style_ref.png \
  --metadata-output outputs/batch_test_run/metadata \
  --masks-output outputs/batch_test_run/masks \
  --pass2-output outputs/batch_test_run \
  --chapter-id chapter_test \
  --engine flux
```
